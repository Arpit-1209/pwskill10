{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0a976e-1228-46c5-83f4-13a4938a4ca8",
   "metadata": {},
   "source": [
    "1. How do you load and run inference on a custom image using the YOLOv8 model (labeled as YOLOv9)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6da174-d898-4ff4-b0dc-82b0d1b5da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.9.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arpit srivastava\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Installing collected packages: ultralytics-thop, py-cpuinfo, opencv-python, ultralytics\n",
      "Successfully installed opencv-python-4.10.0.84 py-cpuinfo-9.0.0 ultralytics-8.3.49 ultralytics-thop-2.0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Arpit Srivastava\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a780b2de-ea5f-41ad-813d-61ebcfd1505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Arpit Srivastava\\download (1).jpeg: 640x384 1 person, 1 dog, 84.9ms\n",
      "Speed: 6.0ms preprocess, 84.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv9 model (YOLOv8 in this case)\n",
    "model = YOLO('yolov8n.pt')  # Replace with the actual model path if needed\n",
    "\n",
    "# Run inference on a custom image\n",
    "results = model('download (1).jpeg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a807a-822d-42e0-a8d8-f96e57209d94",
   "metadata": {},
   "source": [
    "2. How do you load the Faster RCNN model with a ResNet50 backbone and print its architecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "097699d5-1170-470f-a13c-0a3e49f0b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arpit Srivastava\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Arpit Srivastava\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\Arpit Srivastava/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|█████████████████████████████████████████| 160M/160M [02:26<00:00, 1.14MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Load the Faster RCNN model with ResNet50 backbone\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Print the architecture of the model\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc197aa9-9aba-4695-99dd-5127deae51bb",
   "metadata": {},
   "source": [
    "3. How do you perform inference on an online image using the Faster RCNN model and print the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a33fde13-2670-4eb2-9f80-1ba960a09b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 306.2997,  278.9960,  615.9741,  786.9034],\n",
      "        [ 384.1620,  534.4406, 1008.4300,  792.4063],\n",
      "        [ 393.0817,  527.6692,  540.4462,  684.2594],\n",
      "        [  50.4929,  519.7365,  568.7787,  794.8137],\n",
      "        [   0.0000,  350.5025,  227.6613,  760.7053],\n",
      "        [  17.2015,  523.8696,  347.9217,  804.0000],\n",
      "        [   7.3403,  511.3454,  340.6875,  789.7105],\n",
      "        [ 398.7364,  547.0774,  536.2683,  680.8552],\n",
      "        [ 167.1183,  518.5482,  339.1471,  787.4736],\n",
      "        [ 575.2139,  618.3203, 1024.0000,  800.2305],\n",
      "        [  33.5862,  410.1456, 1018.4420,  794.6489],\n",
      "        [ 171.2914,  523.4850,  343.2284,  804.0000],\n",
      "        [  11.6628,  571.2129,  227.2035,  791.1810],\n",
      "        [ 556.5294,  597.9436, 1024.0000,  801.5265],\n",
      "        [ 179.4713,  528.7270,  651.3500,  797.3718],\n",
      "        [   0.0000,  251.9923,   11.7704,  261.6660],\n",
      "        [ 376.3718,  546.6411,  588.5123,  779.7421],\n",
      "        [ 777.2491,  745.6122,  825.9382,  773.7188],\n",
      "        [ 779.8652,  744.4615,  826.2331,  774.3498],\n",
      "        [ 597.8563,  544.8221,  673.5721,  638.8559]]), 'labels': tensor([ 1, 63, 73, 63, 64, 62, 63, 84, 62, 63, 63, 63, 86, 62, 62, 16, 73, 75, 74, 62]), 'scores': tensor([0.9992, 0.9605, 0.8573, 0.8318, 0.7741, 0.4963, 0.4625, 0.3872, 0.3249, 0.2868, 0.2790, 0.2332, 0.1597, 0.1379, 0.1203, 0.1180, 0.0805, 0.0756, 0.0615, 0.0532])}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Load Faster RCNN model with pre-trained weights\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load an image from an online source\n",
    "url = 'https://media.istockphoto.com/id/2039918088/photo/happy-african-american-woman-using-tablet-on-a-cozy-sofa-at-home.jpg?s=1024x1024&w=is&k=20&c=-rdFcTOcILfROUzuBoVmZbEaNAApqSRXjblyHz6CeOY='\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Preprocess the image\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(image_tensor)\n",
    "\n",
    "# Print the predictions (bounding boxes, labels, and scores)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37cb815-5d28-41ce-bc3f-fe5c95970c1d",
   "metadata": {},
   "source": [
    "4. How do you load an image and perform inference using YOLOv9, then display the detected objects with bounding boxes and class labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c8fa38-0271-4ed4-8aaf-311abc35530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 1 dog, 144.8ms\n",
      "Speed: 5.0ms preprocess, 144.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'xywh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the bounding boxes, labels, and confidence scores\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m boxes \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxywh\u001b[49m[\u001b[38;5;241m0\u001b[39m][:, :\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Bounding boxes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mxywh[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Class labels\u001b[39;00m\n\u001b[0;32m     16\u001b[0m scores \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mxywh[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Confidence scores\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'xywh'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv9 model\n",
    "model = YOLO('yolov9t.pt')\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('download (1).jpeg')\n",
    "\n",
    "# Perform inference\n",
    "results = model(image)\n",
    "\n",
    "# Get the bounding boxes, labels, and confidence scores\n",
    "boxes = results.xywh[0][:, :4].cpu().numpy()  # Bounding boxes\n",
    "labels = results.xywh[0][:, 5].cpu().numpy()  # Class labels\n",
    "scores = results.xywh[0][:, 4].cpu().numpy()  # Confidence scores\n",
    "\n",
    "# Draw bounding boxes and labels on the image\n",
    "for box, label, score in zip(boxes, labels, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    cv2.putText(image, f'{model.names[int(label)]}: {score:.2f}', (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Detected Objects', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c52ef3-33e5-4bbd-b35b-2033f4a06d4e",
   "metadata": {},
   "source": [
    "5. How do you display bounding boxes for the detected objects in an image using Faster RCNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556740a1-afa0-4db8-832d-4433c024e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Load Faster RCNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('download (1).jpeg')\n",
    "\n",
    "# Convert image to tensor\n",
    "image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(image_tensor)\n",
    "\n",
    "# Get bounding boxes\n",
    "boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Bounding Boxes', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec29d3-b099-493f-8804-fce116e36387",
   "metadata": {},
   "source": [
    "6. How do you perform inference on a local image using Faster RCNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8357c734-c75d-41e6-8cec-4e06931969a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[   6.0747,  225.7161,  603.1781, 1272.0842],\n",
      "        [  43.6810,  248.2779,  604.0640,  953.6782],\n",
      "        [  10.9060,  363.4500,  234.9849,  939.1548],\n",
      "        [   0.0000,  350.4636,  411.9798, 1038.6139],\n",
      "        [ 644.9882,  725.1860,  698.8099,  786.6296],\n",
      "        [ 644.6409,  719.7424,  698.9259,  784.5071],\n",
      "        [ 277.1775,  598.7109,  530.9061, 1262.1251],\n",
      "        [  97.9248,  549.2142,  601.1274, 1246.4344],\n",
      "        [ 282.2257,  617.4450,  548.7278, 1254.9834],\n",
      "        [   2.7493,  634.0876,  421.1807, 1233.7306],\n",
      "        [ 243.5096,  651.8255,  521.5056, 1250.5190],\n",
      "        [  74.5877,  510.2979,  530.8853, 1036.5032],\n",
      "        [ 539.3710,  723.7611,  614.2542,  825.2762],\n",
      "        [  25.8443,  596.0424,  509.7683, 1261.0477],\n",
      "        [  11.6508,  665.0109,  305.9524, 1034.0255],\n",
      "        [ 540.1844,  725.5382,  607.3673,  823.8063],\n",
      "        [  32.3508,  675.5434,  301.9443,  976.7241],\n",
      "        [ 247.7456,  907.6970,  449.3322, 1256.0381],\n",
      "        [  98.4668,  455.1525,  434.0376,  835.4838],\n",
      "        [   5.3215,  557.1600,   55.1752,  919.4302],\n",
      "        [ 175.2675,  247.5790,  514.6524,  699.3749],\n",
      "        [ 387.3846,  837.4689,  532.0096, 1240.3646],\n",
      "        [ 477.3366,  683.5269,  616.5616,  954.2155],\n",
      "        [ 269.9212,  954.2728,  443.7170, 1260.7772],\n",
      "        [   8.7429,  440.1979,  101.6065,  959.3884],\n",
      "        [ 267.1413,  946.2761,  449.5117, 1267.5912],\n",
      "        [  14.1776,  683.9875,  305.3666, 1046.6982],\n",
      "        [ 559.7595,  707.9111,  638.9657,  831.2882],\n",
      "        [  13.5527,  829.6350,  563.0259, 1280.0000],\n",
      "        [ 637.8590,  718.4286,  701.2835,  786.2605],\n",
      "        [   2.5081,  570.5387,   54.6621,  745.5790]]), 'labels': tensor([ 1, 18,  1,  1,  3,  8, 32, 27, 31, 27, 27, 32, 65, 31, 27,  1, 32, 27, 32,  1, 18, 32, 65, 32,  1, 31, 31, 65, 27,  6,  1]), 'scores': tensor([0.9087, 0.8173, 0.8101, 0.7335, 0.6782, 0.6242, 0.5540, 0.4071, 0.2987, 0.2484, 0.2247, 0.1987, 0.1961, 0.1847, 0.1741, 0.1727, 0.1612, 0.1515, 0.1139, 0.0995, 0.0947, 0.0873, 0.0867, 0.0802, 0.0801, 0.0794, 0.0754, 0.0583, 0.0581, 0.0578, 0.0556])}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Load Faster RCNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load the local image\n",
    "image = Image.open('download (1).jpeg')\n",
    "\n",
    "# Convert the image to tensor\n",
    "image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(image_tensor)\n",
    "\n",
    "# Print predictions (bounding boxes, labels, and scores)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a48d31-cdb6-4c62-ba1f-6a96660be01e",
   "metadata": {},
   "source": [
    "7. How can you change the confidence threshold for YOLO object detection and filter out low-confidence predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e3a49d4-618e-4bfa-83b8-56650c1be734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Arpit Srivastava\\Downloads\\download (1).jpeg: 640x384 1 dog, 119.2ms\n",
      "Speed: 5.0ms preprocess, 119.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv9 model\n",
    "model = YOLO('yolov9t.pt')\n",
    "\n",
    "# Run inference on an image with a confidence threshold of 0.5\n",
    "results = model('download (1).jpeg', conf=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f129f77-898b-4db5-bc8a-f4e8510ecfd3",
   "metadata": {},
   "source": [
    "8. How do you plot the training and validation loss curves for model evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1aa4a85-651b-44ab-8ddb-6ac6b65c9e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of training and validation losses for each epoch\n",
    "train_loss = [0.6, 0.5, 0.4, 0.3]  # Example values\n",
    "val_loss = [0.7, 0.6, 0.5, 0.4]  # Example values\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82491df0-11ed-4936-8d22-27368f22eac3",
   "metadata": {},
   "source": [
    "9. How do you perform inference on multiple images from a local folder using Faster RCNN and display the bounding boxes for each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7319178d-86d9-4240-bf42-0403f1d4617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Load Faster RCNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = 'Downloads/dd'\n",
    "\n",
    "# Loop through images in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to tensor\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)\n",
    "\n",
    "    # Draw bounding boxes on the image\n",
    "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(f'Predictions for {filename}', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff3791-870b-4668-8363-a5adcdde8fea",
   "metadata": {},
   "source": [
    "10. How do you visualize the confidence scores alongside the bounding boxes for detected objects using Faster RCNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "985fca1a-b4a4-4195-8221-88190b686afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Load Faster RCNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread('download (1).jpeg')\n",
    "\n",
    "# Convert image to tensor\n",
    "image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(image_tensor)\n",
    "\n",
    "# Get bounding boxes, labels, and scores\n",
    "boxes = prediction[0]['boxes'].cpu().numpy()\n",
    "scores = prediction[0]['scores'].cpu().numpy()\n",
    "\n",
    "# Draw bounding boxes and confidence scores\n",
    "for box, score in zip(boxes, scores):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "    cv2.putText(image, f'{score:.2f}', (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the image with bounding boxes and confidence scores\n",
    "cv2.imshow('Detected Objects with Scores', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f40bd-deb8-4fc7-92e8-81a37af41eab",
   "metadata": {},
   "source": [
    "11. How can you save the inference results (with bounding boxes) as a new image after performing detection using YOLO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e26c4ab-60f1-4669-acd3-63786b348e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Arpit Srivastava\\Downloads\\download (1).jpeg: 640x384 1 person, 1 dog, 195.7ms\n",
      "Speed: 4.4ms preprocess, 195.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'render'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Arpit Srivastava/Downloads/download (1).jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Get the image with bounding boxes\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m output_image \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Save the image with bounding boxes\u001b[39;00m\n\u001b[0;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, output_image)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'render'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv9 model\n",
    "model = YOLO('yolov9t.pt')\n",
    "\n",
    "# Run inference on an image\n",
    "results = model('download (1).jpeg')\n",
    "\n",
    "# Get the image with bounding boxes\n",
    "output_image = results.render()[0]\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "cv2.imwrite('output_image.jpg', output_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30fd51-80c6-45a2-960f-930e02504650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
